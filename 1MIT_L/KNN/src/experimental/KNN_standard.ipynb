{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "KNN.ipynb",
      "provenance": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_TwylZeyBrrA",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "IMPORTS:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FkIURPrSABP-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pickle\n",
        "import os\n",
        "from os import path\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "import sys\n",
        "import torch\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import datasets, layers, models\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)\n",
        "\n",
        "import cv2\n",
        "import csv\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.image as mpimg\n",
        "from keras.models import Model\n",
        "from PIL import Image\n",
        "import string\n",
        "from keras.callbacks import ModelCheckpoint"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hy0_g-_J6wbW",
        "colab_type": "text"
      },
      "source": [
        "Download data from drive to speed things up"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iMyxEi1H6y2i",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "zip_path = '/content/drive/My Drive/KNN/2017-IWT4S-CarsReId_LP-dataset.zip'\n",
        "!cp \"{zip_path}\" .\n",
        "!unzip -q '2017-IWT4S-CarsReId_LP-dataset.zip'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5Ibqka0jQ4zg",
        "colab_type": "text"
      },
      "source": [
        "Parse csv and load train/test data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0FnBlVqBRFA0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_images = []\n",
        "train_labels = []\n",
        "test_images  = []\n",
        "test_labels  = []\n",
        "\n",
        "with open('trainVal.csv', 'r') as csv_file:\n",
        "    csv_reader = csv.reader(csv_file, delimiter=',')\n",
        "    line_count = 0\n",
        "    for row in csv_reader:\n",
        "        if line_count == 0:\n",
        "            # Skip header row\n",
        "            line_count += 1\n",
        "        else:\n",
        "            if int(row[3]) == 0:\n",
        "                if(len(row[2]) != 7):\n",
        "                    continue\n",
        "                img = cv2.imread(row[1])\n",
        "                if img is None:\n",
        "                    continue\n",
        "                img = cv2.cvtColor(img, cv2.COLOR_RGB2BGR)\n",
        "                res = cv2.resize(img, dsize=(200, 40), interpolation=cv2.INTER_CUBIC)\n",
        "                normalizedImg = np.zeros((200, 40))\n",
        "                normalizedImg = cv2.normalize(res,  normalizedImg, 0, 255, cv2.NORM_MINMAX)\n",
        "                test_labels.append([row[2]])\n",
        "                test_images.append(normalizedImg)\n",
        "            else:\n",
        "                if(len(row[2]) != 7):\n",
        "                    continue\n",
        "                img = cv2.imread(row[1])\n",
        "                if img is None:\n",
        "                    continue\n",
        "                img = cv2.cvtColor(img, cv2.COLOR_RGB2BGR)\n",
        "                res = cv2.resize(img, dsize=(200, 40), interpolation=cv2.INTER_CUBIC)\n",
        "                normalizedImg = np.zeros((200, 40))\n",
        "                normalizedImg = cv2.normalize(res,  normalizedImg, 0, 255, cv2.NORM_MINMAX)\n",
        "                train_labels.append([row[2]])\n",
        "                train_images.append(normalizedImg)\n",
        "\n",
        "train_images = np.asarray(train_images)\n",
        "train_labels = np.asarray(train_labels)\n",
        "test_images  = np.asarray(test_images)\n",
        "test_labels  = np.asarray(test_labels)\n",
        "\n",
        "# Debug\n",
        "print(train_images.shape)\n",
        "print(train_labels.shape)\n",
        "print(test_images.shape)\n",
        "print(test_labels.shape)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GAUeU3L0HySL",
        "colab_type": "text"
      },
      "source": [
        "Convert to 'loss function friendly' format"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vdsKDwraH0br",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Create dict to encode digits to numbers\n",
        "y_map = {}\n",
        "for i,d in enumerate(string.digits+string.ascii_uppercase):\n",
        "    y_map[d] = i\n",
        "\n",
        "# Utility function for split string in char and encode them\n",
        "def split_encode(x):\n",
        "    x = list(x[0])\n",
        "    x = [y_map[d] for d in x]\n",
        "    return x\n",
        "\n",
        "# Transform target\n",
        "train_labels = np.apply_along_axis(split_encode, 1, train_labels)\n",
        "test_labels = np.apply_along_axis(split_encode, 1, test_labels)\n",
        "\n",
        "# Debug\n",
        "print(train_images.shape)\n",
        "print(train_labels.shape)\n",
        "print(test_images.shape)\n",
        "print(test_labels.shape)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2AcCdUk2saUI",
        "colab_type": "text"
      },
      "source": [
        "Class names A-Z, 0-9"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LC95FfS1sboR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "chars  = [chr(i) for i in list(range(ord('A'),ord('Z')+1))]\n",
        "digits = ['0', '1', '2', '3', '4', '5', '6', '7', '8', '9']\n",
        "\n",
        "class_names = digits + chars\n",
        "\n",
        "print(class_names)\n",
        "print(len(class_names))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sjKUDJckeS_q",
        "colab_type": "text"
      },
      "source": [
        "Check few images"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MuPrScWteVeC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plt.figure(figsize=(10,10))\n",
        "for i in range(10):\n",
        "    plt.subplot(5,5,i+1)\n",
        "    plt.xticks([])\n",
        "    plt.yticks([])\n",
        "    plt.grid(False)\n",
        "    plt.imshow(train_images[i], cmap=plt.cm.binary)\n",
        "    plt.xlabel(train_labels[i])\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZbHx4V7Ush5L",
        "colab_type": "text"
      },
      "source": [
        "Create model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tC6NPbAAsjbA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 32,64,128 - filters count\n",
        "# (x, x) is size of convolutional kernel\n",
        "# relu is activation function\n",
        "# batch normalization after each convolutional layer\n",
        "\n",
        "from keras.layers import *\n",
        "\n",
        "inp_dim = (40, 200, 3)\n",
        "x_inp = Input(shape=inp_dim)\n",
        "\n",
        "# First part\n",
        "x = Conv2D(32, (3, 3), use_bias=False, padding='same')(x_inp)\n",
        "x = BatchNormalization()(x)\n",
        "x = Activation(\"relu\")(x)\n",
        "x = Conv2D(32, (3, 3), use_bias=False, padding='same')(x)\n",
        "x = BatchNormalization()(x)\n",
        "x = Activation(\"relu\")(x)\n",
        "x = Conv2D(32, (3, 3), use_bias=False, padding='same')(x)\n",
        "x = BatchNormalization()(x)\n",
        "x = Activation(\"relu\")(x)\n",
        "x = MaxPooling2D((2, 2))(x)\n",
        "\n",
        "# Second part\n",
        "x = Conv2D(64, (3, 3), use_bias=False, padding='same')(x)\n",
        "x = BatchNormalization()(x)\n",
        "x = Activation(\"relu\")(x)\n",
        "x = Conv2D(64, (3, 3), use_bias=False, padding='same')(x)\n",
        "x = BatchNormalization()(x)\n",
        "x = Activation(\"relu\")(x)\n",
        "x = Conv2D(64, (3, 3), use_bias=False, padding='same')(x)\n",
        "x = BatchNormalization()(x)\n",
        "x = Activation(\"relu\")(x)\n",
        "x = MaxPooling2D((2, 2))(x)\n",
        "\n",
        "# Third part\n",
        "x = Conv2D(128, (3, 3), use_bias=False, padding='same')(x)\n",
        "x = BatchNormalization()(x)\n",
        "x = Activation(\"relu\")(x)\n",
        "x = Conv2D(128, (3, 3), use_bias=False, padding='same')(x)\n",
        "x = BatchNormalization()(x)\n",
        "x = Activation(\"relu\")(x)\n",
        "x = Conv2D(128, (3, 3), use_bias=False, padding='same')(x)\n",
        "x = BatchNormalization()(x)\n",
        "x = Activation(\"relu\")(x)\n",
        "x = MaxPooling2D((2, 2))(x)\n",
        "\n",
        "\n",
        "x_out = Flatten()(x)\n",
        "model = Model(x_inp, x_out)\n",
        "\n",
        "branches = []\n",
        "\n",
        "for _ in range(7):\n",
        "    x = Dense(128)(x_out)\n",
        "    x = Dense(36)(x)\n",
        "    x = Activation(\"softmax\")(x)\n",
        "    branches.append(x)\n",
        "\n",
        "final_model = Model(inputs = x_inp, outputs = branches)\n",
        "\n",
        "# Display model architecture\n",
        "final_model.summary()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Pil7CahExHSI",
        "colab_type": "text"
      },
      "source": [
        "Compile and train the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WpJjsM-wxIHt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Checkpoint callback (to save weights after each epoch)\n",
        "filepath = \"/content/drive/My Drive/KNN/model-big-{epoch:02d}.hdf5\"\n",
        "checkpoint = ModelCheckpoint(filepath, monitor='loss', verbose=1, save_best_only=False, save_weights_only=True, mode='auto', period=1)\n",
        "\n",
        "# Adam optimizer with 0.001 learning rate\n",
        "final_model.compile(tf.keras.optimizers.Adam(learning_rate=0.001),\n",
        "                    loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=False),\n",
        "                    metrics=['accuracy'])\n",
        "\n",
        "# Train for 80 epochs\n",
        "history = final_model.fit(train_images, [train_labels[:,i] for i in range(7)], epochs=80,\n",
        "                          validation_data=(test_images, [test_labels[:,i] for i in range(7)]), callbacks=[checkpoint])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OZKd6DWCxK1I",
        "colab_type": "text"
      },
      "source": [
        "Evaluate the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l-cQ59ckxM3j",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plt.plot(history.history['accuracy'], label='accuracy')\n",
        "plt.plot(history.history['val_accuracy'], label = 'val_accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.ylim([0.5, 1])\n",
        "plt.legend(loc='lower right')\n",
        "\n",
        "test_loss, test_acc = model.evaluate(test_images,  test_labels, verbose=2)\n",
        "\n",
        "print(test_acc)"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}
